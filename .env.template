# AI Provider設定
# 'openai', 'bedrock', 'ollama' から選択
AI_PROVIDER=openai

# OpenAI設定
OPENAI_API_KEY=your_openai_api_key_here
AI_MODEL=gpt-3.5-turbo

# AWS Bedrockの設定
# AI_PROVIDER=bedrockの場合に使用
# AWS_PROFILE=your_aws_profile # AWS CLIプロファイル名
AWS_REGION=us-east-1
# AI_MODEL=anthropic.claude-v2 # Bedrockで使用するモデル

# Ollama設定
# AI_PROVIDER=ollamaの場合に使用
# OLLAMA_BASE_URL=http://localhost:11434
# AI_MODEL=llama2 # Ollamaで使用するモデル

# 共通設定
# AI_TEMPERATURE=0.7 # 生成の多様性 (0-1)
# AI_MAX_TOKENS=500 # 生成する最大トークン数
